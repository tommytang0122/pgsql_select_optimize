#!/usr/bin/env python3
"""
FastAPI å¾Œç«¯ - è®€å– data_100k è³‡æ–™è¡¨
æ”¯æ´é€£ç·šæ± é–‹é—œåŠŸèƒ½ã€å®‰å…¨æ€§å„ªåŒ– (Rate Limit, CORS, Env Vars)
"""

import os
from dotenv import load_dotenv

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

from fastapi import FastAPI, Query, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.gzip import GZipMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse, JSONResponse
import psycopg2
from psycopg2.extras import RealDictCursor
from psycopg2 import pool
from typing import Optional
from contextlib import contextmanager
import time

# Rate Limiting
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

# ============================================
# é…ç½®è¼‰å…¥
# ============================================
# Debug æ¨¡å¼
DEBUG_MODE = os.getenv("DEBUG", "false").lower() == "true"

# CORS è¨­å®š
CORS_ORIGINS = os.getenv("CORS_ORIGINS", "http://localhost:8000").split(",")

# GZip å£“ç¸®è¨­å®š
USE_GZIP = False             # é–‹é—œï¼šTrue=å•Ÿç”¨ GZip, False=åœç”¨ (æœ¬åœ°æ¸¬è©¦å»ºè­°é—œé–‰)
GZIP_MIN_SIZE = 500          # æœ€å°å£“ç¸®å¤§å° (bytes)

# è³‡æ–™åº«é€£ç·šè¨­å®š (è®€å–ç’°å¢ƒè®Šæ•¸)
DB_CONFIG = {
    'host': os.getenv("DB_HOST", "localhost"),
    'port': int(os.getenv("DB_PORT", 5433)),
    'database': os.getenv("DB_NAME", "testdb"),
    'user': os.getenv("DB_USER", "testuser"),
    'password': os.getenv("DB_PASSWORD", "testpass")
}

# é€£ç·šæ± è¨­å®š
USE_CONNECTION_POOL = False  # é–‹é—œï¼šTrue=ä½¿ç”¨é€£ç·šæ± , False=ä¸ä½¿ç”¨
POOL_MIN_CONN = 2           # æœ€å°é€£ç·šæ•¸
POOL_MAX_CONN = 10          # æœ€å¤§é€£ç·šæ•¸

# åˆå§‹åŒ– Limiter
limiter = Limiter(key_func=get_remote_address)

app = FastAPI(
    title="PostgreSQL Data API",
    description="API for querying data_100k table",
    version="1.0.0",
    debug=DEBUG_MODE
)

# è¨»å†Š Rate Limit éŒ¯èª¤è™•ç†
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

# å•Ÿç”¨ CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=CORS_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å•Ÿç”¨ GZip å£“ç¸®
if USE_GZIP:
    app.add_middleware(GZipMiddleware, minimum_size=GZIP_MIN_SIZE)
    print(f"âœ… GZip å£“ç¸®å·²å•Ÿç”¨ (minimum_size={GZIP_MIN_SIZE})")
else:
    print("âš ï¸ GZip å£“ç¸®å·²åœç”¨")

# é€£ç·šæ± å¯¦ä¾‹
connection_pool: Optional[pool.ThreadedConnectionPool] = None

def init_connection_pool():
    """åˆå§‹åŒ–é€£ç·šæ± """
    global connection_pool
    if USE_CONNECTION_POOL and connection_pool is None:
        try:
            connection_pool = pool.ThreadedConnectionPool(
                POOL_MIN_CONN,
                POOL_MAX_CONN,
                **DB_CONFIG
            )
            print(f"âœ… é€£ç·šæ± å·²å•Ÿç”¨ (min={POOL_MIN_CONN}, max={POOL_MAX_CONN})")
        except Exception as e:
            print(f"âŒ é€£ç·šæ± åˆå§‹åŒ–å¤±æ•—: {e}")

def close_connection_pool():
    """é—œé–‰é€£ç·šæ± """
    global connection_pool
    if connection_pool:
        connection_pool.closeall()
        connection_pool = None
        print("ðŸ”Œ é€£ç·šæ± å·²é—œé–‰")

@contextmanager
def get_db_connection():
    """å–å¾—è³‡æ–™åº«é€£ç·š (Context Manager)"""
    conn = None
    try:
        if USE_CONNECTION_POOL and connection_pool:
            conn = connection_pool.getconn()
        else:
            conn = psycopg2.connect(**DB_CONFIG)
        yield conn
    except psycopg2.Error as e:
        print(f"âŒ è³‡æ–™åº«éŒ¯èª¤: {e}")
        raise HTTPException(status_code=500, detail="Database connection error")
    finally:
        if conn:
            if USE_CONNECTION_POOL and connection_pool:
                connection_pool.putconn(conn)
            else:
                conn.close()

# å•Ÿå‹•/é—œé–‰äº‹ä»¶
@app.on_event("startup")
async def startup_event():
    print(f"ðŸ›¡ï¸  CORS Origins: {CORS_ORIGINS}")
    print(f"ðŸ›¡ï¸  Debug Mode: {DEBUG_MODE}")
    if USE_CONNECTION_POOL:
        init_connection_pool()
    else:
        print("âš ï¸ é€£ç·šæ± å·²åœç”¨ï¼Œä½¿ç”¨ç›´æŽ¥é€£ç·šæ¨¡å¼")

@app.on_event("shutdown")
async def shutdown_event():
    close_connection_pool()

# API ç«¯é»ž
@app.get("/")
async def root():
    """è¼‰å…¥å‰ç«¯é é¢"""
    return FileResponse("static/index.html")

app.mount("/static", StaticFiles(directory="static"), name="static")

@app.get("/api/pool/status")
async def get_pool_status():
    """å–å¾—é€£ç·šæ± ç‹€æ…‹"""
    return {
        "use_connection_pool": USE_CONNECTION_POOL,
        "pool_initialized": connection_pool is not None,
        "pool_min_conn": POOL_MIN_CONN if USE_CONNECTION_POOL else None,
        "pool_max_conn": POOL_MAX_CONN if USE_CONNECTION_POOL else None,
    }

@app.get("/data/count")
@limiter.limit("60/minute")
async def get_count(request: Request):
    """å–å¾—è³‡æ–™ç¸½æ•¸"""
    start_time = time.time()
    with get_db_connection() as conn:
        cursor = conn.cursor(cursor_factory=RealDictCursor)
        try:
            cursor.execute("SELECT COUNT(*) as count FROM data_100k")
            result = cursor.fetchone()
            elapsed = time.time() - start_time
            return {
                "count": result["count"],
                "query_time_ms": round(elapsed * 1000, 2),
                "connection_pool": USE_CONNECTION_POOL
            }
        finally:
            cursor.close()

@app.get("/data")
@limiter.limit("30/minute")
async def get_data(
    request: Request,
    limit: int = Query(default=100, ge=1, le=10000, description="æ¯é ç­†æ•¸ (Max 10000)"),
    offset: int = Query(default=0, ge=0, description="åç§»é‡"),
    columns: Optional[str] = Query(default=None, description="æŒ‡å®šæ¬„ä½ (é€—è™Ÿåˆ†éš”)")
):
    """å–å¾—è³‡æ–™åˆ—è¡¨ (æ”¯æ´åˆ†é )"""
    start_time = time.time()
    
    # å¼·åˆ¶é™åˆ¶ limit ä¸Šé™ï¼Œé˜²æ­¢å¤§é‡æ•¸æ“šè«‹æ±‚
    limit = min(limit, 10000)
    
    if columns:
        valid_columns = set(['id'] + [chr(ord('a') + i) for i in range(26)])
        requested_columns = [c.strip().lower() for c in columns.split(',')]
        for col in requested_columns:
            if col not in valid_columns:
                raise HTTPException(status_code=400, detail=f"ç„¡æ•ˆçš„æ¬„ä½åç¨±: {col}")
        select_columns = ', '.join(requested_columns)
    else:
        select_columns = '*'
    
    with get_db_connection() as conn:
        cursor = conn.cursor(cursor_factory=RealDictCursor)
        try:
            # ä½¿ç”¨åƒæ•¸åŒ–æŸ¥è©¢ï¼Œé€™è£¡çš„ limit å’Œ offset å·²ç¶“ç”± FastAPI é©—è­‰ç‚º int
            query = f"SELECT {select_columns} FROM data_100k ORDER BY id LIMIT %s OFFSET %s"
            cursor.execute(query, (limit, offset))
            rows = cursor.fetchall()
            elapsed = time.time() - start_time
            return {
                "data": rows,
                "count": len(rows),
                "limit": limit,
                "offset": offset,
                "query_time_ms": round(elapsed * 1000, 2),
                "connection_pool": USE_CONNECTION_POOL
            }
        finally:
            cursor.close()

@app.get("/data/all")
@limiter.limit("5/minute")
async def get_all_data(request: Request):
    """
    ä¸€æ¬¡å–å¾—å…¨éƒ¨è³‡æ–™ (é«˜è² è¼‰ç«¯é»žï¼Œåš´æ ¼é™æµ)
    """
    start_time = time.time()
    with get_db_connection() as conn:
        cursor = conn.cursor(cursor_factory=RealDictCursor)
        try:
            cursor.execute("SELECT * FROM data_100k ORDER BY id")
            rows = cursor.fetchall()
            elapsed = time.time() - start_time
            return {
                "data": rows,
                "count": len(rows),
                "query_time_ms": round(elapsed * 1000, 2),
                "connection_pool": USE_CONNECTION_POOL
            }
        finally:
            cursor.close()

@app.get("/data/search")
@limiter.limit("30/minute")
async def search_data(
    request: Request,
    column: str = Query(..., description="æœå°‹æ¬„ä½ (a-z)"),
    min_value: Optional[int] = Query(default=None),
    max_value: Optional[int] = Query(default=None),
    exact_value: Optional[int] = Query(default=None),
    limit: int = Query(default=100, ge=1, le=10000)
):
    """æœå°‹è³‡æ–™"""
    start_time = time.time()
    
    valid_columns = set([chr(ord('a') + i) for i in range(26)])
    column = column.strip().lower()
    
    if column not in valid_columns:
        raise HTTPException(status_code=400, detail=f"ç„¡æ•ˆçš„æ¬„ä½åç¨±: {column}")
    
    conditions = []
    params = []
    
    if exact_value is not None:
        conditions.append(f"{column} = %s")
        params.append(exact_value)
    else:
        if min_value is not None:
            conditions.append(f"{column} >= %s")
            params.append(min_value)
        if max_value is not None:
            conditions.append(f"{column} <= %s")
            params.append(max_value)
    
    if not conditions:
        raise HTTPException(status_code=400, detail="è«‹æä¾›æœå°‹æ¢ä»¶")
    
    with get_db_connection() as conn:
        cursor = conn.cursor(cursor_factory=RealDictCursor)
        try:
            where_clause = ' AND '.join(conditions)
            # æ¬„ä½åç¨±ç¶“éŽç™½åå–®é©—è­‰ï¼Œæ˜¯å®‰å…¨çš„
            query = f"SELECT * FROM data_100k WHERE {where_clause} ORDER BY id LIMIT %s"
            params.append(limit)
            cursor.execute(query, params)
            rows = cursor.fetchall()
            elapsed = time.time() - start_time
            return {
                "data": rows,
                "count": len(rows),
                "search_column": column,
                "query_time_ms": round(elapsed * 1000, 2),
                "connection_pool": USE_CONNECTION_POOL
            }
        finally:
            cursor.close()

@app.get("/data/{id}")
@limiter.limit("60/minute")
async def get_data_by_id(request: Request, id: int):
    """å–å¾—å–®ç­†è³‡æ–™"""
    start_time = time.time()
    with get_db_connection() as conn:
        cursor = conn.cursor(cursor_factory=RealDictCursor)
        try:
            cursor.execute("SELECT * FROM data_100k WHERE id = %s", (id,))
            row = cursor.fetchone()
            if not row:
                raise HTTPException(status_code=404, detail=f"æ‰¾ä¸åˆ° id={id} çš„è³‡æ–™")
            elapsed = time.time() - start_time
            return {
                "data": row,
                "query_time_ms": round(elapsed * 1000, 2),
                "connection_pool": USE_CONNECTION_POOL
            }
        finally:
            cursor.close()

if __name__ == "__main__":
    import uvicorn
    # ä½¿ç”¨ç’°å¢ƒè®Šæ•¸æŽ§åˆ¶ reload
    reload = os.getenv("DEBUG", "false").lower() == "true"
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=reload)
